{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOUhNzM7KnyUY8hGIB1CVG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teddy-teem/deep-learning/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek90katZ5U5Y",
        "outputId": "823e8173-6cbe-4ec4-b8ed-659048a471ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "GNi_b2pm51LC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"About Data Science Mentorship Program\n",
        "\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2.0)\n",
        "The total course fee for the DSMP course is Rs 10,600. This includes the fee for both DSMP 1.0 and DSMP 2.0\n",
        "\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is about 6-8 months.\n",
        "\n",
        "Are Deep Learning and NLP a part of the DSMP 2.0  course?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes, all our sessions are recorded, so even if you miss a session you can login into our portal and watch the recording as per your convenience.\n",
        "\n",
        "Where can I find the class schedule?\n",
        "You will find the class schedule in your course dashboard once you enroll for the course.\n",
        "\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "\n",
        "\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish.\n",
        "\n",
        "How will I be informed about the upcoming class?\n",
        "You will get mail from our side before every session once you enroll in the course.\n",
        "\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely. However, you’ll need to be consistent.\n",
        "\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program any time.\n",
        "\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you’re enrolled in the course, you will be able to see all the past content in your dashboard.\n",
        "\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "\n",
        "Will we do case studies in the program?\n",
        "Yes, there are 5 end to end case studies and multiple smaller projects.\n",
        "\n",
        "Do we offer any student discounts or promo codes?\n",
        "We do offer discounts on our courses a few times a year, and we announce them through our social media channels.\n",
        "\n",
        "On how many devices can I watch the videos simultaneously?\n",
        "You can watch the videos on one device at a time.\n",
        "\n",
        "\n",
        "\n",
        "Do you provide notes for the lectures?\n",
        "We do not provide notes for our lectures. We encourage students to make their own notes as it aids in study retention.\n",
        "\n",
        "What is the difference between being a paid member on your YouTube channel and your website?\n",
        "While the content on our YouTube channel and website is similar, enrolling through our website offers additional benefits such as doubt clearance support and access to an exclusive community of learners on Discord and more.\n",
        "\n",
        "Do I get access to your YouTube channel as a paid member after enrolling through your website?\n",
        "No, the YouTube channel membership is separate from what we offer on our website.\n",
        "\n",
        "Is there any upcoming batch for the Data Science Mentorship Program?\n",
        "Currently, we do not have any plans to launch a new batch for DSMP. However, all previous lectures are available as recordings, allowing you to learn at your own pace.\n",
        "\n",
        "Do you provide doubt clearance for the projects uploaded on CampusX YouTube channel?\n",
        "We do not provide doubt clearance for any of our videos or projects uploaded on YouTube. However, you can ask your doubts in our Discord channel or in the comments section.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Payment/Registration related questions\n",
        "\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "\n",
        "What if I don’t like the course after making the payment? What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment. To apply for refund, send us an email at support@campusx.in\n",
        "\n",
        "I am living outside India and I am not able to make the payment on the website. What should I do?\n",
        "You can contact us by sending a mail at support@campusx.in\n",
        "\n",
        "I am from Pakistan and I am unable to make the payment?\n",
        "We currently do not have the option to accept payment from Pakistan directly. If you’d still like to enroll for the course, you may ask a friend or family member living outside Pakistan to make the fee payment on your behalf.\n",
        "\n",
        "Do you accept PayPal as a payment method?\n",
        "Yes, we do. Please contact us at support@campusx.in for more details on using PayPal for payment.\n",
        "\n",
        "I cannot pay the DSMP 2.0 fee as a one-time payment, is there any way to make a payment in installments?\n",
        "At the moment, we do not have a monthly payment plan for the DSMP 2.0 course. However, if you have financial constraints, you can enroll in DSMP 1.0 by paying 799/- a month. Once you complete the course, you may apply for a discount coupon from the website.\n",
        "\n",
        "\n",
        "Post registration queries\n",
        "\n",
        "Till when can I view the paid videos on the website?\n",
        "You can watch the videos till your subscription is valid, that is 3 years from the date of purchase for DSMP 2.0 and 2 years for DSMP 1.0\n",
        "\n",
        "Why is lifetime validity not provided?\n",
        "Because of the low course fee.\n",
        "\n",
        "Do you assist with personal projects?\n",
        "We do not provide support for personal projects due to time constraints and current commitments.\n",
        "\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearing session.\n",
        "\n",
        "\n",
        "\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select “past week's doubt” in the doubt clearance google form.\n",
        "\n",
        "What is the validity of Doubt Support?\n",
        "You will get doubt support for 1 year from the data of registration.\n",
        "\n",
        "\n",
        "\n",
        "Certificate and Placement Assistance related queries\n",
        "\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 10,600\n",
        "You have to attempt all the course assessments.\n",
        "\n",
        "I have read that Job Preparation is a part of this program. What comes under Job Preparation?\n",
        "This is to clarify that Job Preparation does not mean Placement guarantee. We don't guarantee our learners any jobs or for that matter even interview calls. If you are planning to join this course just for placements, we’re afraid that this course might not be the best for you.\n",
        "\n",
        "Here is what comes under Job Preparation\n",
        "Portfolio Building sessions.\n",
        "Interview Questions.\n",
        "Sessions with industry mentors.\n",
        "Discussion on Job hunting strategies.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "d3SOpEOA6Vpb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnKyRgUr69o-",
        "outputId": "67e7108c-d8e8-44b8-fcf2-13203db678c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokeniz\n",
        "\n",
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "P1GcIbbJ7h86"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocabulary\n",
        "\n",
        "vocab = {'<unk>': 0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQCjBC6Y7ydH",
        "outputId": "5ca339f7-3a2b-4790-d340-9ce4f946fa57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract sentences from data\n",
        "input_sentences = document.split('.')"
      ],
      "metadata": {
        "id": "tl9MCWET8ZzG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "  numerical_sentence=[]\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "  return numerical_sentence"
      ],
      "metadata": {
        "id": "nH05_dV_9B6s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#numerical sentences\n",
        "input_numerical_sentences = []\n",
        "for sentence in input_sentences:\n",
        "  res = text_to_indices(word_tokenize(sentence.lower()), vocab)\n",
        "  input_numerical_sentences.append(res)\n",
        "len(input_numerical_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcaRhJsr8vCe",
        "outputId": "d69a8c90-3086-476f-a9fc-b0526f6a68c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traing_sequence = []\n",
        "for sentence in input_numerical_sentences:\n",
        "  for i in range(1, len(sentence)):\n",
        "    traing_sequence.append(sentence[:i+1])\n",
        "# len(traing_sequence)\n",
        "traing_sequence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8S_t6mx-G-c",
        "outputId": "4893a9b4-e9aa-4fa6-ec33-385199c8b352"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Padding\n",
        "padded_training_sequence = []\n",
        "len_list = []\n",
        "for sequence in traing_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "max_len = max(len_list)\n",
        "print(max_len)\n",
        "\n",
        "for sequence in traing_sequence:\n",
        "  padded_training_sequence.append([0]*(max_len-len(sequence)) + sequence)\n",
        "len(padded_training_sequence[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UetPDxXD_bpk",
        "outputId": "03a8616f-f309-4db7-b95e-05a3383368b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)\n",
        "padded_training_sequence.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFLRnJtdAx7h",
        "outputId": "e4871bda-79d0-4981-acf0-f6062b5080f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1160, 53])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:, :-1]\n",
        "Y = padded_training_sequence[:, -1]"
      ],
      "metadata": {
        "id": "xHEgce_NBF6J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.X[index], self.y[index]\n",
        ""
      ],
      "metadata": {
        "id": "JRGIvY7wBbPJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X, Y)\n",
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31dlwINRB4z2",
        "outputId": "51240880-1f4d-450b-aac2-bfcf89e98cc9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1160, 52]), torch.Size([1160]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "5vhU9lmPCBcc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embeded =self.embedding(x)\n",
        "    intermediate_states, (final_hidden_state, final_cell_state) = self.lstm(embeded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output\n",
        ""
      ],
      "metadata": {
        "id": "RKHRWfTHCG1R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example with single item ->> Main model below\n",
        "x = nn.Embedding(len(vocab), 100)\n",
        "y = nn.LSTM(100, 150, batch_first=True)\n",
        "z = nn.Linear(150, len(vocab))\n",
        "a = dataset[0][0].unsqueeze(0)\n",
        "b = x(a)\n",
        "c, d = y(b)\n",
        "e, f =  d\n",
        "f.shape\n",
        "z(f.squeeze(0)).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p68EkI0HPqk",
        "outputId": "92b9bf6b-c486-4b07-bcb1-bc96a16c9384"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 352])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "h0_wfqRdHtmk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "Learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=Learning_rate)\n"
      ],
      "metadata": {
        "id": "2lbbqEjxKSbX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0;\n",
        "  for x, y in dataloader:\n",
        "    x.to(device), y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f'Epoch: {epoch+1}, Loss: {total_loss/len(dataloader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zr-rM34Kl_R",
        "outputId": "58ff1b0f-0400-4628-b960-d9c1a946b872"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 5.66275287318874\n",
            "Epoch: 2, Loss: 5.006022775495374\n",
            "Epoch: 3, Loss: 4.620555993672964\n",
            "Epoch: 4, Loss: 4.197022051424594\n",
            "Epoch: 5, Loss: 3.8021554689149597\n",
            "Epoch: 6, Loss: 3.4075716379526497\n",
            "Epoch: 7, Loss: 3.029614016816423\n",
            "Epoch: 8, Loss: 2.696822888142354\n",
            "Epoch: 9, Loss: 2.3998907482301868\n",
            "Epoch: 10, Loss: 2.1071439530398393\n",
            "Epoch: 11, Loss: 1.8469035657676491\n",
            "Epoch: 12, Loss: 1.6128028566772874\n",
            "Epoch: 13, Loss: 1.413062833450936\n",
            "Epoch: 14, Loss: 1.2282224684148222\n",
            "Epoch: 15, Loss: 1.0652547994175472\n",
            "Epoch: 16, Loss: 0.9367614404575245\n",
            "Epoch: 17, Loss: 0.8147198026244705\n",
            "Epoch: 18, Loss: 0.719545999894271\n",
            "Epoch: 19, Loss: 0.6394835203080564\n",
            "Epoch: 20, Loss: 0.5698609867611447\n",
            "Epoch: 21, Loss: 0.5119010789974315\n",
            "Epoch: 22, Loss: 0.4580898180201247\n",
            "Epoch: 23, Loss: 0.4122038983009957\n",
            "Epoch: 24, Loss: 0.3829249526197846\n",
            "Epoch: 25, Loss: 0.34970812459249756\n",
            "Epoch: 26, Loss: 0.32002144890862544\n",
            "Epoch: 27, Loss: 0.2919019589553008\n",
            "Epoch: 28, Loss: 0.2715678500968057\n",
            "Epoch: 29, Loss: 0.2538230213764551\n",
            "Epoch: 30, Loss: 0.2397613674402237\n",
            "Epoch: 31, Loss: 0.22662272888260918\n",
            "Epoch: 32, Loss: 0.21405924876799454\n",
            "Epoch: 33, Loss: 0.20150977534216805\n",
            "Epoch: 34, Loss: 0.19342608608909556\n",
            "Epoch: 35, Loss: 0.18332751759806196\n",
            "Epoch: 36, Loss: 0.1818667527388882\n",
            "Epoch: 37, Loss: 0.17360431902311943\n",
            "Epoch: 38, Loss: 0.1640810283857423\n",
            "Epoch: 39, Loss: 0.16045861066998662\n",
            "Epoch: 40, Loss: 0.15332193108829292\n",
            "Epoch: 41, Loss: 0.14967730701775164\n",
            "Epoch: 42, Loss: 0.14552021701190923\n",
            "Epoch: 43, Loss: 0.14018755083954013\n",
            "Epoch: 44, Loss: 0.13804811682250048\n",
            "Epoch: 45, Loss: 0.13331518966603922\n",
            "Epoch: 46, Loss: 0.12979607586119626\n",
            "Epoch: 47, Loss: 0.13451322631256\n",
            "Epoch: 48, Loss: 0.13050566080051498\n",
            "Epoch: 49, Loss: 0.12872258835547679\n",
            "Epoch: 50, Loss: 0.12663944820697243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, vocab, sentence):\n",
        "  # tokinzed_text =\n",
        "  tokenized_text = word_tokenize(sentence.lower())\n",
        "\n",
        "  # text to numerical text\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "  # padding\n",
        "  padded_text = torch.tensor([0] * (max_len-len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(padded_text);\n",
        "\n",
        "  #predicted index\n",
        "  value, index = torch.max(output, dim=1)\n",
        "\n",
        "  #merge with text\n",
        "  return sentence+list(vocab.keys())[index]\n"
      ],
      "metadata": {
        "id": "lziEJQ5GKpFe"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, \"Hi, I am late \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ryASkZ0lMYlH",
        "outputId": "fd23bc4f-3b1a-493b-85d1-c102a828692c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi, I am late ,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "num_tokens = 10\n",
        "input_text = \"I have read that Job\"\n",
        "for i in range(num_tokens):\n",
        " output = prediction(model, vocab, input_text)\n",
        " print(output)\n",
        " input_text = (output+\" \")\n",
        " time.sleep(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fGpzS0bOtEL",
        "outputId": "0ed01fb9-4b0e-4672-d336-b39bf244f795"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have read that Jobpreparation\n",
            "I have read that Jobpreparation and\n",
            "I have read that Jobpreparation and i\n",
            "I have read that Jobpreparation and i am\n",
            "I have read that Jobpreparation and i am unable\n",
            "I have read that Jobpreparation and i am unable to\n",
            "I have read that Jobpreparation and i am unable to make\n",
            "I have read that Jobpreparation and i am unable to make the\n",
            "I have read that Jobpreparation and i am unable to make the payment\n",
            "I have read that Jobpreparation and i am unable to make the payment ?\n"
          ]
        }
      ]
    }
  ]
}